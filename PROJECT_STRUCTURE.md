# Financial RAG System - Project Structure

## ğŸ“ Complete Directory Structure

```
financial-rag-system/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                # Quick start guide
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example                 # Environment template
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Docker container config
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Multi-container setup
â”œâ”€â”€ ğŸ”§ setup.sh                     # Automated setup script
â”œâ”€â”€ ğŸ”§ run.sh                       # Quick run commands
â”‚
â”œâ”€â”€ ğŸ“‚ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py                 # Package initialization
â”‚   â”œâ”€â”€ utils.py                    # Helper functions & utilities
â”‚   â”œâ”€â”€ data_ingestion.py           # PDF processing & chunking
â”‚   â”œâ”€â”€ embeddings.py               # Embedding generation
â”‚   â”œâ”€â”€ vector_store.py             # ChromaDB management
â”‚   â”œâ”€â”€ rag_pipeline.py             # Core RAG logic
â”‚   â”œâ”€â”€ evaluation.py               # Metrics & evaluation
â”‚   â”œâ”€â”€ api.py                      # FastAPI REST endpoints
â”‚   â””â”€â”€ streamlit_app.py            # Streamlit UI dashboard
â”‚
â”œâ”€â”€ ğŸ“‚ config/                      # Configuration files
â”‚   â””â”€â”€ config.yaml                 # System configuration
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        # Data storage
â”‚   â”œâ”€â”€ raw/                        # Original PDF files
â”‚   â”‚   â””â”€â”€ README.txt              # Data directory guide
â”‚   â”œâ”€â”€ processed/                  # Processed chunks
â”‚   â””â”€â”€ chroma_db/                  # Vector database
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                       # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_pipeline.py            # Pipeline tests
â”‚   â””â”€â”€ test_api.py                 # API endpoint tests
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     # Helper scripts
â”‚   â””â”€â”€ process_documents.py        # Document processing script
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                   # Jupyter notebooks
â”‚   â””â”€â”€ evaluation.ipynb            # Analysis notebook
â”‚
â””â”€â”€ ğŸ“‚ logs/                        # Application logs
    â””â”€â”€ (auto-generated log files)
```

## ğŸ“‹ File Descriptions

### Core Application Files

| File | Purpose | Key Features |
|------|---------|--------------|
| `src/rag_pipeline.py` | Main RAG system | Query processing, LLM integration, cost tracking |
| `src/vector_store.py` | Vector database | ChromaDB management, similarity search |
| `src/data_ingestion.py` | Document processing | PDF parsing, chunking, metadata extraction |
| `src/embeddings.py` | Embedding generation | OpenAI embeddings, batch processing |
| `src/evaluation.py` | System evaluation | Metrics calculation, testing framework |

### User Interfaces

| File | Purpose | Access |
|------|---------|--------|
| `src/streamlit_app.py` | Web dashboard | http://localhost:8501 |
| `src/api.py` | REST API | http://localhost:8000/docs |

### Configuration

| File | Purpose |
|------|---------|
| `config/config.yaml` | System settings (models, parameters) |
| `.env` | Environment variables (API keys) |
| `requirements.txt` | Python dependencies |

### Documentation

| File | Purpose |
|------|---------|
| `README.md` | Complete project documentation |
| `QUICKSTART.md` | 5-minute setup guide |
| `PROJECT_STRUCTURE.md` | This file - project organization |

### Deployment

| File | Purpose |
|------|---------|
| `Dockerfile` | Container definition |
| `docker-compose.yml` | Multi-service orchestration |
| `setup.sh` | Automated setup script |
| `run.sh` | Quick launch commands |

## ğŸ”§ Key Components Breakdown

### 1. RAG Pipeline (`src/rag_pipeline.py`)

**What it does:**
- Processes user queries
- Retrieves relevant documents from vector store
- Generates answers using LLM
- Tracks costs and performance metrics

**Key Classes:**
- `RAGPipeline`: Main pipeline orchestrator

**Methods:**
- `query()`: Execute RAG query
- `get_cost_summary()`: Get cost tracking data

### 2. Vector Store (`src/vector_store.py`)

**What it does:**
- Manages ChromaDB vector database
- Stores document embeddings
- Performs similarity search
- Handles filtering and retrieval

**Key Classes:**
- `VectorStoreManager`: Database management

**Methods:**
- `add_documents()`: Index new documents
- `query()`: Search for similar documents
- `get_collection_stats()`: Get database stats

### 3. Data Ingestion (`src/data_ingestion.py`)

**What it does:**
- Loads PDF files
- Extracts text and metadata
- Chunks documents intelligently
- Prepares data for embedding

**Key Classes:**
- `DocumentProcessor`: PDF processing pipeline

**Methods:**
- `load_pdf()`: Read PDF files
- `chunk_document()`: Split into chunks
- `process_directory()`: Batch processing

### 4. Embeddings (`src/embeddings.py`)

**What it does:**
- Generates vector embeddings
- Batch processing for efficiency
- Cost estimation
- Manages OpenAI API calls

**Key Classes:**
- `EmbeddingGenerator`: Embedding creation

**Methods:**
- `embed_query()`: Single text embedding
- `embed_documents()`: Batch embedding
- `estimate_embedding_cost()`: Cost calculation

### 5. Evaluation (`src/evaluation.py`)

**What it does:**
- Automated testing suite
- Metrics calculation
- Performance benchmarking
- Quality assessment

**Key Classes:**
- `RAGEvaluator`: System evaluation

**Metrics:**
- Answer Relevance (0.0-1.0)
- Context Precision (0.0-1.0)
- Faithfulness Score (0.0-1.0)
- Latency & Cost

## ğŸ¯ Data Flow

```
1. User Query
   â†“
2. Query Embedding (embeddings.py)
   â†“
3. Vector Search (vector_store.py)
   â†“
4. Document Retrieval
   â†“
5. Context Formation
   â†“
6. LLM Generation (rag_pipeline.py)
   â†“
7. Answer + Sources + Metrics
```

## ğŸ“Š Configuration Options

### `config/config.yaml`

```yaml
embeddings:
  model: "text-embedding-3-small"  # Embedding model
  dimension: 1536                  # Vector dimension
  batch_size: 100                  # Batch processing size

llm:
  model: "gpt-4-turbo-preview"     # LLM model
  temperature: 0.1                 # Randomness (0-1)
  max_tokens: 1000                 # Max response length

retrieval:
  top_k: 4                         # Documents to retrieve
  similarity_threshold: 0.7        # Minimum similarity

chunking:
  chunk_size: 1000                 # Characters per chunk
  chunk_overlap: 200               # Overlap between chunks

cost_limits:
  daily_max: 10.0                  # Max daily cost (USD)
  per_query_max: 0.10              # Max per query
```

## ğŸš€ Quick Commands

### Setup
```bash
./setup.sh                    # Automated setup
```

### Run Applications
```bash
./run.sh streamlit            # Web UI
./run.sh api                  # REST API
./run.sh docker               # Both with Docker
```

### Development
```bash
./run.sh test                 # Run tests
./run.sh eval                 # Run evaluation
```

### Process Documents
```bash
python scripts/process_documents.py
```

## ğŸ“ˆ Extending the System

### Add a New LLM Provider

1. Install provider SDK in `requirements.txt`
2. Add configuration in `config/config.yaml`
3. Modify `src/rag_pipeline.py` to support new provider
4. Update tests

### Add New Evaluation Metrics

1. Add metric function in `src/evaluation.py`
2. Update `RAGEvaluator` class
3. Add to config `evaluation.metrics`
4. Run evaluation

### Add New API Endpoints

1. Define endpoint in `src/api.py`
2. Add request/response models
3. Update API documentation
4. Add tests in `tests/test_api.py`

## ğŸ” Security Notes

### Sensitive Files (Never Commit)
- `.env` - Contains API keys
- `data/chroma_db/` - Vector database
- `logs/` - May contain query data
- `*.pdf` in `data/raw/` - Source documents

### Protected by `.gitignore`
All sensitive files are already excluded from Git.

## ğŸ“¦ Production Deployment

### Docker Production
```bash
docker build -t financial-rag:prod .
docker run -p 8501:8501 -e OPENAI_API_KEY=$KEY financial-rag:prod
```

### Cloud Deployment
- **Streamlit Cloud**: Push to GitHub, connect at share.streamlit.io
- **AWS ECS**: Use Dockerfile with ECS task definition
- **Google Cloud Run**: Deploy container with `gcloud run deploy`
- **Azure Container Apps**: Deploy with Azure CLI

## ğŸ¤ Contributing

When adding features:
1. Follow existing code structure
2. Add tests in `tests/`
3. Update relevant documentation
4. Ensure all tests pass
5. Add to CHANGELOG

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

---

**Built by Febin Varghese**
Data Scientist | ML Engineer | RAG Systems Expert
